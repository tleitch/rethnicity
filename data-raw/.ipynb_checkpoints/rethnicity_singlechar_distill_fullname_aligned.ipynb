{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Zdu8rFoKxyf"
      },
      "source": [
        "# Note"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTpDydcEKo18"
      },
      "outputs": [],
      "source": [
        "# model on fullnames but make sure that last names aligned at the same position\n",
        "# this is to overcome the fullname model only focus on firstname part"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hgD1DqMK03m"
      },
      "source": [
        "# Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taMAZqezgDun"
      },
      "outputs": [],
      "source": [
        "# change keras default GPU\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # first gpu\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" # second gpu\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" # runs in cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPIPSqox9Wcb"
      },
      "outputs": [],
      "source": [
        "# pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfzOqkAFNUGv",
        "outputId": "9a9d6555-4cfd-49db-f618-2631ce3cb01a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Apr 16 16:30:16 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24HWCEA89jk_",
        "outputId": "93fe692b-70e3-489b-cea7-296c37a94836"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSEGoTH49pb_",
        "outputId": "156670e4-3320-497f-8157-294ec209fbd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "cd drive/MyDrive/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOJP04Jh9vGh",
        "outputId": "dd4bdde1-cb23-4db6-ff5b-3e1edc5c9826"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow.keras as keras\n",
        "import tensorflow as tf\n",
        "print(keras.__version__)\n",
        "#print(tf.__version__)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dA4Rg9_e9yFd"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"nmzpAgeSexFL.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "tDflDwWJ95vP",
        "outputId": "0b874033-beb2-40bf-97c2-09f02775813e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Unnamed: 0 name_first    name_last       zip5 sex  race        age\n",
              "0                  1  Elizabeth       Walker      32643   F     5  59.049315\n",
              "1                  2      Alton       Palmer      32643   M     5  77.854795\n",
              "2                  3     Alicia     Mc Cleod      32607   F     3  54.402740\n",
              "3                  4       Dale  Scarborough      32643   M     5  69.868493\n",
              "4                  5     Daniel       Walker      32640   M     5  65.572603\n",
              "...              ...        ...          ...        ...  ..   ...        ...\n",
              "13605732    13710354    William      Walters      32428   M     5  74.487671\n",
              "13605733    13710355    Matthew       Sawyer      32428   M     5  36.526027\n",
              "13605734    13710356     Janine       Thomas      32428   F     5  33.857534\n",
              "13605735    13710357      Angel     Campbell      32431   F     7  22.397260\n",
              "13605736    13710358        Jeb       Bruner  324282053   M     5  23.742466\n",
              "\n",
              "[13605737 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6f7e8c25-17d3-4978-b783-e65cdf5cf059\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>name_first</th>\n",
              "      <th>name_last</th>\n",
              "      <th>zip5</th>\n",
              "      <th>sex</th>\n",
              "      <th>race</th>\n",
              "      <th>age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Elizabeth</td>\n",
              "      <td>Walker</td>\n",
              "      <td>32643</td>\n",
              "      <td>F</td>\n",
              "      <td>5</td>\n",
              "      <td>59.049315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Alton</td>\n",
              "      <td>Palmer</td>\n",
              "      <td>32643</td>\n",
              "      <td>M</td>\n",
              "      <td>5</td>\n",
              "      <td>77.854795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Alicia</td>\n",
              "      <td>Mc Cleod</td>\n",
              "      <td>32607</td>\n",
              "      <td>F</td>\n",
              "      <td>3</td>\n",
              "      <td>54.402740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Dale</td>\n",
              "      <td>Scarborough</td>\n",
              "      <td>32643</td>\n",
              "      <td>M</td>\n",
              "      <td>5</td>\n",
              "      <td>69.868493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Daniel</td>\n",
              "      <td>Walker</td>\n",
              "      <td>32640</td>\n",
              "      <td>M</td>\n",
              "      <td>5</td>\n",
              "      <td>65.572603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13605732</th>\n",
              "      <td>13710354</td>\n",
              "      <td>William</td>\n",
              "      <td>Walters</td>\n",
              "      <td>32428</td>\n",
              "      <td>M</td>\n",
              "      <td>5</td>\n",
              "      <td>74.487671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13605733</th>\n",
              "      <td>13710355</td>\n",
              "      <td>Matthew</td>\n",
              "      <td>Sawyer</td>\n",
              "      <td>32428</td>\n",
              "      <td>M</td>\n",
              "      <td>5</td>\n",
              "      <td>36.526027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13605734</th>\n",
              "      <td>13710356</td>\n",
              "      <td>Janine</td>\n",
              "      <td>Thomas</td>\n",
              "      <td>32428</td>\n",
              "      <td>F</td>\n",
              "      <td>5</td>\n",
              "      <td>33.857534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13605735</th>\n",
              "      <td>13710357</td>\n",
              "      <td>Angel</td>\n",
              "      <td>Campbell</td>\n",
              "      <td>32431</td>\n",
              "      <td>F</td>\n",
              "      <td>7</td>\n",
              "      <td>22.397260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13605736</th>\n",
              "      <td>13710358</td>\n",
              "      <td>Jeb</td>\n",
              "      <td>Bruner</td>\n",
              "      <td>324282053</td>\n",
              "      <td>M</td>\n",
              "      <td>5</td>\n",
              "      <td>23.742466</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13605737 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f7e8c25-17d3-4978-b783-e65cdf5cf059')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6f7e8c25-17d3-4978-b783-e65cdf5cf059 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6f7e8c25-17d3-4978-b783-e65cdf5cf059');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.loc[df['race'].isin([2,3,4,5])]"
      ],
      "metadata": {
        "id": "NQH1a7HuFU6A"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4KgkSMG3-HDZ"
      },
      "outputs": [],
      "source": [
        "# create ASCII dictionary\n",
        "chars = ['E'] + [chr(i) for i in range(97,123)] + [' ', 'U']\n",
        "id2char = {i:j for i,j in enumerate(chars)}\n",
        "char2id = {j:i for i,j in enumerate(chars)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4_Ezcz9_dS1"
      },
      "outputs": [],
      "source": [
        "# the characters here are all ASCII, good\n",
        "# for name in df['name_combine'].tolist():\n",
        "#     namechars = list(name)\n",
        "#     for nc in namechars:\n",
        "#         if nc not in char2id:\n",
        "#             print(nc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5QnywdgANNCo"
      },
      "outputs": [],
      "source": [
        "def name2id(name, l = 10):\n",
        "    ids = [0] * l\n",
        "    for i, c in enumerate(name):\n",
        "        if i < l:\n",
        "            if c.isalpha():\n",
        "                ids[i] = char2id.get(c, char2id['U'])\n",
        "            elif c in string.punctuation:\n",
        "                ids[i] = char2id.get(c, char2id[' '])\n",
        "            else:\n",
        "                ids[i] = char2id.get(c, char2id['U'])\n",
        "    return ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "S8-cTDqCMl2T"
      },
      "outputs": [],
      "source": [
        "X = [name2id(fn.lower()) + name2id(ln.lower()) for fn, ln in zip(df['name_first'], df['name_last'])]\n",
        "y = [int(i) for i in df['race'].tolist()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "GaFlIZS4QXTP"
      },
      "outputs": [],
      "source": [
        "# convert the output (y) from 2-5 to 0-3\n",
        "y = [i-2 for i in y]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "z4_-WcyAQXTP"
      },
      "outputs": [],
      "source": [
        "# Split train and test dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8CsGdf1BIUf",
        "outputId": "b970926c-02e3-46fa-b0ab-e7e84c2af5c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "distribution of all data points {0: 252986, 1: 1836866, 2: 2167700, 3: 8685610}\n",
            "distribution of all training data {0: 202361, 1: 1469726, 2: 1735192, 3: 6947250}\n",
            "distribution of all testing data {0: 50625, 1: 367140, 2: 432508, 3: 1738360}\n"
          ]
        }
      ],
      "source": [
        "# check the distribution\n",
        "print('distribution of all data points', {i: y.count(i) for i in set(y)})\n",
        "print('distribution of all training data', {i: y_train.count(i) for i in set(y)})\n",
        "print('distribution of all testing data', {i: y_test.count(i) for i in set(y)})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dj_Z8WulSnvZ"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWw0_KaPMz0P",
        "outputId": "8c96ccde-1493-4d1d-e25d-d9bb2516610d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10354529 train sequences\n",
            "2588633 test sequences\n",
            "Pad sequences (samples x time)\n",
            "X_train shape: (10354529, 20)\n",
            "X_test shape: (2588633, 20)\n",
            "4 classes\n",
            "Convert class vector to binary class matrix (for use with categorical_crossentropy)\n",
            "y_train shape: (10354529, 4)\n",
            "y_test shape: (2588633, 4)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.layers import LSTM, Bidirectional\n",
        "\n",
        "num_words = len(id2char)\n",
        "feature_len = 20 # cut texts after this number of words (among top max_features most common words)\n",
        "batch_size = 512\n",
        "\n",
        "print(len(X_train), 'train sequences')\n",
        "print(len(X_test), 'test sequences')\n",
        "\n",
        "print('Pad sequences (samples x time)')\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=feature_len)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=feature_len)\n",
        "print('X_train shape:', X_train.shape)\n",
        "print('X_test shape:', X_test.shape)\n",
        "\n",
        "num_classes = 4 # np.max(y_train) + 1\n",
        "print(num_classes, 'classes')\n",
        "\n",
        "print('Convert class vector to binary class matrix '\n",
        "      '(for use with categorical_crossentropy)')\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('y_test shape:', y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nvOzuySY3LJ",
        "outputId": "41e7ef55-7b4a-409c-a0b5-dbbe65d14c8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "16179/16179 [==============================] - 7326s 452ms/step - loss: 0.4448 - accuracy: 0.8421 - val_loss: 0.3951 - val_accuracy: 0.8607\n",
            "Epoch 2/10\n",
            "16179/16179 [==============================] - 7341s 454ms/step - loss: 0.3903 - accuracy: 0.8623 - val_loss: 0.3859 - val_accuracy: 0.8641\n",
            "Epoch 3/10\n",
            "16179/16179 [==============================] - 7348s 454ms/step - loss: 0.3830 - accuracy: 0.8648 - val_loss: 0.3843 - val_accuracy: 0.8646\n",
            "Epoch 4/10\n",
            "16179/16179 [==============================] - 7353s 454ms/step - loss: 0.3807 - accuracy: 0.8654 - val_loss: 0.3822 - val_accuracy: 0.8654\n",
            "Epoch 5/10\n",
            " 7456/16179 [============>.................] - ETA: 1:00:43 - loss: 0.3797 - accuracy: 0.8658"
          ]
        }
      ],
      "source": [
        "# simple train-test\n",
        "# first build\n",
        "model = Sequential()\n",
        "model.add(Embedding(num_words, 256, input_length=feature_len))\n",
        "# try out bi-directional LSTM\n",
        "model.add(Bidirectional(LSTM(512, return_sequences=True, dropout=0.2)))\n",
        "model.add(Bidirectional(LSTM(512, return_sequences=True, dropout=0.2)))\n",
        "model.add(Bidirectional(LSTM(512, return_sequences=True, dropout=0.2)))\n",
        "model.add(Bidirectional(LSTM(512, dropout=0.2)))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# choose between learning rates\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "\n",
        "# train model\n",
        "model.fit(X_train, y_train, batch_size=batch_size, epochs=10, validation_split=0.2, verbose=1, callbacks=[callback])\n",
        "score, acc = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-6NPzoJkE-C"
      },
      "outputs": [],
      "source": [
        "# now lets' test\n",
        "y_pred = model.predict(X_test, batch_size=batch_size, verbose=1)\n",
        "y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "\n",
        "print(classification_report(np.argmax(y_test, axis=1), y_pred_bool))\n",
        "print(confusion_matrix(np.argmax(y_test, axis=1), y_pred_bool))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgQrbQybMGEZ"
      },
      "outputs": [],
      "source": [
        "# Use full data set to train saved model\n",
        "\n",
        "\n",
        "X_train = sequence.pad_sequences(X, maxlen=feature_len)\n",
        "y_train = keras.utils.to_categorical(y, num_classes)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('y_train shape:', x_train.shape)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(num_words, 256, input_length=feature_len))\n",
        "# try out bi-directional LSTM\n",
        "model.add(Bidirectional(LSTM(512, return_sequences=True, dropout=0.2)))\n",
        "model.add(Bidirectional(LSTM(512, return_sequences=True, dropout=0.2)))\n",
        "model.add(Bidirectional(LSTM(512, return_sequences=True, dropout=0.2)))\n",
        "model.add(Bidirectional(LSTM(512, dropout=0.2)))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# choose between learning rates\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "\n",
        "# train model\n",
        "model.fit(X_train, y_train, batch_size=batch_size, epochs=10, validation_split=0.2, verbose=1, callbacks=[callback])\n",
        "score, acc = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=1)\n",
        "\n",
        "\n",
        "model.save('fullname_aligned_fulldata.h5', include_optimizer=False)\n",
        "model.save('fullname_aligned_opt_fulldata.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Bf-vMTgxnLnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dad83e52-2f2d-4a42-ec76-4121803d0ff3",
        "id": "71FS-9VLnM6p"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "327/327 [==============================] - 50s 148ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.81     41861\n",
            "           1       0.76      0.73      0.75     41904\n",
            "           2       0.85      0.87      0.86     41940\n",
            "           3       0.66      0.74      0.70     41707\n",
            "\n",
            "    accuracy                           0.78    167412\n",
            "   macro avg       0.78      0.78      0.78    167412\n",
            "weighted avg       0.78      0.78      0.78    167412\n",
            "\n",
            "[[31824  2338  2980  4719]\n",
            " [ 1461 30797  1110  8536]\n",
            " [ 1706  1062 36637  2535]\n",
            " [ 1943  6496  2386 30882]]\n"
          ]
        }
      ],
      "source": [
        "# now lets' test again with full model on original test set to compare\n",
        "y_pred = model.predict(X_test, batch_size=batch_size, verbose=1)\n",
        "y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "\n",
        "print(classification_report(np.argmax(y, axis=1), y_pred_bool))\n",
        "print(confusion_matrix(np.argmax(y_test, axis=1), y_pred_bool))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0u9yV6N2jl9"
      },
      "source": [
        "# Distill the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpKLoGXWoOPJ"
      },
      "outputs": [],
      "source": [
        "# TODO: shall we try model distillation for compressing the model size?\n",
        "# so that we will have smaller model to work with\n",
        "class Distiller(keras.Model):\n",
        "    def __init__(self, student, teacher):\n",
        "        super(Distiller, self).__init__()\n",
        "        self.teacher = teacher\n",
        "        self.student = student\n",
        "\n",
        "    def compile(\n",
        "        self,\n",
        "        optimizer,\n",
        "        metrics,\n",
        "        student_loss_fn,\n",
        "        distillation_loss_fn,\n",
        "        alpha=0.1,\n",
        "        temperature=3,\n",
        "    ):\n",
        "        \"\"\" Configure the distiller.\n",
        "\n",
        "        Args:\n",
        "            optimizer: Keras optimizer for the student weights\n",
        "            metrics: Keras metrics for evaluation\n",
        "            student_loss_fn: Loss function of difference between student\n",
        "                predictions and ground-truth\n",
        "            distillation_loss_fn: Loss function of difference between soft\n",
        "                student predictions and soft teacher predictions\n",
        "            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n",
        "            temperature: Temperature for softening probability distributions.\n",
        "                Larger temperature gives softer distributions.\n",
        "        \"\"\"\n",
        "        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics)\n",
        "        self.student_loss_fn = student_loss_fn\n",
        "        self.distillation_loss_fn = distillation_loss_fn\n",
        "        self.alpha = alpha\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # Unpack data\n",
        "        x, y = data\n",
        "\n",
        "        # Forward pass of teacher\n",
        "        teacher_predictions = self.teacher(x, training=False)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass of student\n",
        "            student_predictions = self.student(x, training=True)\n",
        "\n",
        "            # Compute losses\n",
        "            student_loss = self.student_loss_fn(y, student_predictions)\n",
        "            distillation_loss = self.distillation_loss_fn(\n",
        "                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n",
        "                tf.nn.softmax(student_predictions / self.temperature, axis=1),\n",
        "            )\n",
        "            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.student.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        # Update the metrics configured in `compile()`.\n",
        "        self.compiled_metrics.update_state(y, student_predictions)\n",
        "\n",
        "        # Return a dict of performance\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update(\n",
        "            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n",
        "        )\n",
        "        return results\n",
        "\n",
        "    def test_step(self, data):\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "\n",
        "        # Compute predictions\n",
        "        y_prediction = self.student(x, training=False)\n",
        "\n",
        "        # Calculate the loss\n",
        "        student_loss = self.student_loss_fn(y, y_prediction)\n",
        "\n",
        "        # Update the metrics.\n",
        "        self.compiled_metrics.update_state(y, y_prediction)\n",
        "\n",
        "        # Return a dict of performance\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update({\"student_loss\": student_loss})\n",
        "        return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X981CoGW2lmo"
      },
      "outputs": [],
      "source": [
        "# Create the student\n",
        "student = keras.Sequential(\n",
        "    [\n",
        "        Embedding(num_words, 32, input_length=feature_len),\n",
        "        Bidirectional(LSTM(16, return_sequences=True, dropout=0.2)),\n",
        "        Bidirectional(LSTM(16, return_sequences=True, dropout=0.2)),\n",
        "        Bidirectional(LSTM(16, return_sequences=True, dropout=0.2)),\n",
        "        Bidirectional(LSTM(16, dropout=0.2)),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ],\n",
        "    name=\"student\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjFVdBqx2xbz",
        "outputId": "b967ad40-b069-4704-cbdf-2980e90ba49a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "20927/20927 [==============================] - 693s 32ms/step - categorical_accuracy: 0.6034 - student_loss: 0.9379 - distillation_loss: 3.7233e-04\n",
            "Epoch 2/40\n",
            "20927/20927 [==============================] - 707s 34ms/step - categorical_accuracy: 0.6674 - student_loss: 0.8243 - distillation_loss: 2.9024e-04\n",
            "Epoch 3/40\n",
            "20927/20927 [==============================] - 708s 34ms/step - categorical_accuracy: 0.6830 - student_loss: 0.7935 - distillation_loss: 2.6745e-04\n",
            "Epoch 4/40\n",
            "20927/20927 [==============================] - 715s 34ms/step - categorical_accuracy: 0.6910 - student_loss: 0.7768 - distillation_loss: 2.5557e-04\n",
            "Epoch 5/40\n",
            "20927/20927 [==============================] - 713s 34ms/step - categorical_accuracy: 0.6962 - student_loss: 0.7667 - distillation_loss: 2.4801e-04\n",
            "Epoch 6/40\n",
            "20927/20927 [==============================] - 710s 34ms/step - categorical_accuracy: 0.6998 - student_loss: 0.7603 - distillation_loss: 2.4307e-04\n",
            "Epoch 7/40\n",
            "20927/20927 [==============================] - 709s 34ms/step - categorical_accuracy: 0.7019 - student_loss: 0.7546 - distillation_loss: 2.3917e-04\n",
            "Epoch 8/40\n",
            "20927/20927 [==============================] - 721s 34ms/step - categorical_accuracy: 0.7047 - student_loss: 0.7499 - distillation_loss: 2.3564e-04\n",
            "Epoch 9/40\n",
            "20927/20927 [==============================] - 721s 34ms/step - categorical_accuracy: 0.7062 - student_loss: 0.7466 - distillation_loss: 2.3339e-04\n",
            "Epoch 10/40\n",
            "20927/20927 [==============================] - 724s 35ms/step - categorical_accuracy: 0.7074 - student_loss: 0.7437 - distillation_loss: 2.3120e-04\n",
            "Epoch 11/40\n",
            "20927/20927 [==============================] - 726s 35ms/step - categorical_accuracy: 0.7090 - student_loss: 0.7415 - distillation_loss: 2.2977e-04\n",
            "Epoch 12/40\n",
            "20927/20927 [==============================] - 728s 35ms/step - categorical_accuracy: 0.7099 - student_loss: 0.7393 - distillation_loss: 2.2802e-04\n",
            "Epoch 13/40\n",
            "20927/20927 [==============================] - 697s 33ms/step - categorical_accuracy: 0.7105 - student_loss: 0.7373 - distillation_loss: 2.2682e-04\n",
            "Epoch 14/40\n",
            "20927/20927 [==============================] - 686s 33ms/step - categorical_accuracy: 0.7116 - student_loss: 0.7354 - distillation_loss: 2.2533e-04\n",
            "Epoch 15/40\n",
            "20927/20927 [==============================] - 683s 33ms/step - categorical_accuracy: 0.7126 - student_loss: 0.7335 - distillation_loss: 2.2416e-04\n",
            "Epoch 16/40\n",
            "20927/20927 [==============================] - 681s 33ms/step - categorical_accuracy: 0.7134 - student_loss: 0.7329 - distillation_loss: 2.2348e-04\n",
            "Epoch 17/40\n",
            "20927/20927 [==============================] - 679s 32ms/step - categorical_accuracy: 0.7134 - student_loss: 0.7314 - distillation_loss: 2.2281e-04\n",
            "Epoch 18/40\n",
            "20927/20927 [==============================] - 679s 32ms/step - categorical_accuracy: 0.7138 - student_loss: 0.7301 - distillation_loss: 2.2178e-04\n",
            "Epoch 19/40\n",
            "20927/20927 [==============================] - 680s 32ms/step - categorical_accuracy: 0.7144 - student_loss: 0.7292 - distillation_loss: 2.2109e-04\n",
            "Epoch 20/40\n",
            "20927/20927 [==============================] - 680s 32ms/step - categorical_accuracy: 0.7146 - student_loss: 0.7284 - distillation_loss: 2.2057e-04\n",
            "Epoch 21/40\n",
            "20927/20927 [==============================] - 680s 32ms/step - categorical_accuracy: 0.7153 - student_loss: 0.7274 - distillation_loss: 2.1962e-04\n",
            "Epoch 22/40\n",
            "20927/20927 [==============================] - 680s 32ms/step - categorical_accuracy: 0.7152 - student_loss: 0.7266 - distillation_loss: 2.1894e-04\n",
            "Epoch 23/40\n",
            "20927/20927 [==============================] - 680s 32ms/step - categorical_accuracy: 0.7162 - student_loss: 0.7254 - distillation_loss: 2.1852e-04\n",
            "Epoch 24/40\n",
            "20927/20927 [==============================] - 686s 33ms/step - categorical_accuracy: 0.7164 - student_loss: 0.7246 - distillation_loss: 2.1777e-04\n",
            "Epoch 25/40\n",
            "20927/20927 [==============================] - 693s 33ms/step - categorical_accuracy: 0.7163 - student_loss: 0.7245 - distillation_loss: 2.1766e-04\n",
            "Epoch 26/40\n",
            "20927/20927 [==============================] - 687s 33ms/step - categorical_accuracy: 0.7169 - student_loss: 0.7235 - distillation_loss: 2.1712e-04\n",
            "Epoch 27/40\n",
            "20927/20927 [==============================] - 694s 33ms/step - categorical_accuracy: 0.7174 - student_loss: 0.7228 - distillation_loss: 2.1641e-04\n",
            "Epoch 28/40\n",
            "20927/20927 [==============================] - 710s 34ms/step - categorical_accuracy: 0.7180 - student_loss: 0.7222 - distillation_loss: 2.1617e-04\n",
            "Epoch 29/40\n",
            "20927/20927 [==============================] - 719s 34ms/step - categorical_accuracy: 0.7180 - student_loss: 0.7216 - distillation_loss: 2.1581e-04\n",
            "Epoch 30/40\n",
            "20927/20927 [==============================] - 717s 34ms/step - categorical_accuracy: 0.7180 - student_loss: 0.7213 - distillation_loss: 2.1551e-04\n",
            "Epoch 31/40\n",
            "20927/20927 [==============================] - 717s 34ms/step - categorical_accuracy: 0.7185 - student_loss: 0.7200 - distillation_loss: 2.1493e-04\n",
            "Epoch 32/40\n",
            "20927/20927 [==============================] - 694s 33ms/step - categorical_accuracy: 0.7197 - student_loss: 0.7196 - distillation_loss: 2.1411e-04\n",
            "Epoch 33/40\n",
            "20927/20927 [==============================] - 720s 34ms/step - categorical_accuracy: 0.7190 - student_loss: 0.7192 - distillation_loss: 2.1410e-04\n",
            "Epoch 34/40\n",
            "20927/20927 [==============================] - 692s 33ms/step - categorical_accuracy: 0.7193 - student_loss: 0.7193 - distillation_loss: 2.1410e-04\n",
            "Epoch 35/40\n",
            "20927/20927 [==============================] - 691s 33ms/step - categorical_accuracy: 0.7199 - student_loss: 0.7184 - distillation_loss: 2.1350e-04\n",
            "Epoch 36/40\n",
            "20927/20927 [==============================] - 685s 33ms/step - categorical_accuracy: 0.7198 - student_loss: 0.7182 - distillation_loss: 2.1355e-04\n",
            "Epoch 37/40\n",
            "20927/20927 [==============================] - 684s 33ms/step - categorical_accuracy: 0.7203 - student_loss: 0.7176 - distillation_loss: 2.1297e-04\n",
            "Epoch 38/40\n",
            "20927/20927 [==============================] - 687s 33ms/step - categorical_accuracy: 0.7206 - student_loss: 0.7167 - distillation_loss: 2.1230e-04\n",
            "Epoch 39/40\n",
            "20927/20927 [==============================] - 689s 33ms/step - categorical_accuracy: 0.7204 - student_loss: 0.7163 - distillation_loss: 2.1237e-04\n",
            "Epoch 40/40\n",
            "20927/20927 [==============================] - 693s 33ms/step - categorical_accuracy: 0.7204 - student_loss: 0.7167 - distillation_loss: 2.1232e-04\n",
            "5232/5232 [==============================] - 44s 8ms/step - categorical_accuracy: 0.7372 - student_loss: 0.6842\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.7372231483459473, 0.5687428116798401]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initialize and compile distiller\n",
        "distiller = Distiller(student=student, teacher=model)\n",
        "distiller.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=[keras.metrics.CategoricalAccuracy()],\n",
        "    student_loss_fn=keras.losses.CategoricalCrossentropy(),\n",
        "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
        "    alpha=0.1,\n",
        "    temperature=10,\n",
        ")\n",
        "\n",
        "# Distill teacher to student\n",
        "distiller.fit(X_train, y_train, epochs=40)\n",
        "\n",
        "# Evaluate student on test dataset\n",
        "distiller.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSa_Mz1W24NY",
        "outputId": "2ddeae1f-81c6-4bec-e74f-b7f2f2923983"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 197/5232 [>.............................] - ETA: 43s"
          ]
        }
      ],
      "source": [
        "y_pred = distiller.student.predict(X_test, batch_size=32, verbose=1)\n",
        "y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "\n",
        "print(classification_report(np.argmax(y_test, axis=1), y_pred_bool))\n",
        "print(confusion_matrix(np.argmax(y_test, axis=1), y_pred_bool))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2BHkrW929xf"
      },
      "outputs": [],
      "source": [
        "distiller.student.save('fullname_aligned_distill_opt.h5')\n",
        "distiller.student.save('fullname_aligned_distill.h5', include_optimizer=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Sq0AoaL3oxZ"
      },
      "source": [
        "# Tune the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twHc9ikEQXTU"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Bqz-zDjQXTU"
      },
      "outputs": [],
      "source": [
        "model.get_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpWFwcbCQXTU"
      },
      "outputs": [],
      "source": [
        "model.optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vrwONT8QXTU"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "K.eval(model.optimizer.lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lC2QHV06RZ2S"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# files.download('fullname_2_ethnicity_bilstm.h5') "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "rethnicity_singlechar_distill_fullname_aligned.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}